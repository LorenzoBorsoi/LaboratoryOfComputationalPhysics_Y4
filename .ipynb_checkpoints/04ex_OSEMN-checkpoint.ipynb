{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OSEMN Exercises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1\\. Create a random list of number and then save it to a text file named \"simple_data.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.16927737859609027, 0.6577715656794223, 0.9801841221912455, 0.24099694097847435, 0.2694413234486842, 0.7890549480945879, 0.40052911285262693, 0.7622832338955932, 0.16746780778801673, 0.09297268505059864]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "li=[random.random() for i in range(10)]\n",
    "print(li)\n",
    "\n",
    "with open(\"simple_data.txt\", mode=\"w\") as sd:\n",
    "    for dat in li:\n",
    "        sd.write(\"{} \".format(dat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2\\. Create a random matrix of 5x5 and then save it to a text file named \"data.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy.random as npr\n",
    "\n",
    "m=npr.randn(5,5)\n",
    "\n",
    "with open(\"data.txt\", mode=\"w\") as d:\n",
    "    for r in range(5):\n",
    "        for l in range(5):\n",
    "            d.write(\"{} \".format(m[r,l]))\n",
    "        d.write(\"\\n\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3\\. Load the saved txt file of point 2 and convert it to a csv file (by hand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "int() can't convert non-string with explicit base",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-88-87671490213c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m110111\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"data.txt\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"r\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: int() can't convert non-string with explicit base"
     ]
    }
   ],
   "source": [
    "s=\"\"\n",
    "with open(\"data.txt\", mode=\"r\") as d:\n",
    "    for line in d:\n",
    "        for n in line.split(\" \"):\n",
    "            if n==\"\\n\": s+=\"\\n\"\n",
    "            else:\n",
    "                s+=\"{}, \".format(n)\n",
    "                \n",
    "with open(\"data.txt\", mode=\"w\") as d:\n",
    "    d.write(s)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4\\. load the binary file named *credit_card.dat* and convert the data into the real credit-card number.\n",
    "Each line correspond to a credit card number.\n",
    "Each character is composed by 6 bit (even the space) and the last 4 bit are just a padding\n",
    "\n",
    "**hint**: use the `chr()` function to convert a number to a char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of the credit cards: \n",
      "7648 5673 3775 2271\n",
      "3257 8247 3354 2266\n",
      "2722 0001 4011 6652\n",
      "0661 3063 3742 3150\n",
      "0432 1608 1462 4742\n",
      "5827 2027 8785 7303\n",
      "5774 8528 2087 1117\n",
      "8140 1210 6352 2845\n",
      "5764 1133 7301 7100\n",
      "6456 1737 4126 6726\n",
      "1228 8631 7382 0000\n",
      "7051 0160 5374 3166\n",
      "0618 3587 1630 6376\n",
      "1545 5454 7444 5636\n",
      "6735 3116 3202 6834\n",
      "7287 5011 1547 8413\n",
      "7033 2607 3328 4200\n",
      "2568 5244 1874 5024\n",
      "1684 2253 7570 7118\n",
      "0672 2576 0575 6631\n",
      "6332 8353 8787 1340\n",
      "1813 3361 1175 4211\n",
      "2477 6450 8840 2368\n",
      "5512 3505 2563 1326\n",
      "3083 7882 0621 0025\n",
      "4521 5148 8045 0334\n",
      "7563 3654 8713 5787\n",
      "8324 2664 0476 5561\n",
      "0565 2504 7168 3510\n",
      "5107 5507 1767 0738\n",
      "2462 1821 2448 1443\n",
      "2788 0638 6861 6554\n",
      "5851 5873 5474 0547\n",
      "0670 1004 4013 2655\n",
      "5874 5506 3048 0806\n",
      "2805 5401 8462 1260\n",
      "5083 8406 6310 1862\n",
      "1076 1445 3013 2266\n",
      "8440 4804 4844 5277\n",
      "4758 6141 0686 1387\n",
      "7586 0675 0315 2568\n",
      "2544 1258 7432 5165\n",
      "3474 5023 4434 5626\n",
      "1410 0270 0434 5086\n",
      "7315 4446 1104 4215\n",
      "0224 7742 8300 0266\n",
      "0170 2700 3145 0640\n",
      "2006 2437 8054 1600\n",
      "8142 4055 1776 0026\n",
      "3026 7380 1241 1084\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of the credit cards: \")\n",
    "\n",
    "with open(\"credit_card.dat\", mode=\"r\") as d:\n",
    "    for line in d:\n",
    "        cred=\"\"\n",
    "        for l in range(int((len(line)-5)/6)):\n",
    "            c=\"\"\n",
    "            for i in range(6):\n",
    "                c+=line[i+6*l]\n",
    "            cred+=\"{}\".format(chr(int(c,2)))\n",
    "        print(cred)\n",
    "        \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5\\. Load the file \"user_data.json\", filter the data by the \"CreditCardType\" field equals to \"American Express\". Than save the data a to CSV."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6\\. Load the file from this url: [https://www.dropbox.com/s/7u3lm737ogbqsg8/mushrooms_categorized.csv?dl=1](https://www.dropbox.com/s/7u3lm737ogbqsg8/mushrooms_categorized.csv?dl=1) with Pandas. \n",
    "+ Explore the data (see the info of the data)\n",
    "+ Draw the istogram of the 'class' field. Decribe wath yuou see\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7\\. Load the remote file [https://www.dropbox.com/s/vkl89yce7xjdq4n/regression_generated.csv?dl=1](https://www.dropbox.com/s/vkl89yce7xjdq4n/regression_generated.csv?dl=1) with Pandas and plot a scatter plot all possible combination of the following fields:\n",
    "    \n",
    "  + features_1\n",
    "  + features_2\n",
    "  + features_3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8\\. Load the same file of point 6, and convert the file to json with Pandas."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
